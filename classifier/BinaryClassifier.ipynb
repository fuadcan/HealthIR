{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,sys\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doclist = pd.read_excel('data/merged.xlsx','cleaned')\n",
    "doclist = doclist.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6533, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doclist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    4469\n",
       " 1    1948\n",
       " 0     116\n",
       "Name: CREDIBLE, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doclist['CREDIBLE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS_DIR = '/media/ludwig/story/DecisionRunDocs/docs_28topics/'\n",
    "SAVE_DIR = 'model/'\n",
    "docs = []\n",
    "for docname in doclist['DOCID']:\n",
    "    with open(DOCS_DIR + docname) as fh:\n",
    "        docs.append(fh.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doclist['DOC'] = docs\n",
    "doclist = doclist[~doclist['DOCID'].duplicated()]\n",
    "doclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    4469\n",
       " 1    1948\n",
       " 0     116\n",
       "Name: CREDIBLE, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doclist['CREDIBLE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(doclist,test_size = .2, random_state = 156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6533, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doclist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test, val   = train_test_split(test,test_size = .5, random_state = 156)\n",
    "# del train['DOC']\n",
    "# del test['DOC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = train['DOC'].values.tolist()\n",
    "X_test  = test['DOC'].values.tolist()\n",
    "# X_val   = val['DOC'].values.tolist()\n",
    "\n",
    "y_train, y_test = train['CREDIBLE'], test['CREDIBLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='char', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(4, 4), preprocessor=None, stop_words=None,\n",
       "        ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load\n",
    "\n",
    "## Input to sklearn\n",
    "vect = CountVectorizer(ngram_range=(4,4), analyzer='char', binary=True)\n",
    "logreg = LogisticRegression()\n",
    "pline  = Pipeline([('vectorizer', vect), ('logreg', logreg)])\n",
    "pline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = pline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test): 0.9462809917355371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[482,   1,  10],\n",
       "       [  8,   1,   7],\n",
       "       [ 11,   2, 204]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy (Test):', metrics.accuracy_score(y_test, y_preds))\n",
    "# print('Test F1 score (Test):', metrics.f1_score(y_test, y_pred_class, average='macro'))\n",
    "metrics.confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After some adjustments in the Data (e.g. correcting different jugments for same documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doclist = pd.read_excel('merged_v2.xlsx')\n",
    "doclist = doclist.reset_index()\n",
    "doclist = doclist[['DOCID','source','CREDIBLE.1']]\n",
    "doclist.columns = ['DOCID', 'SOURCE', 'CREDIBLE']\n",
    "doclist.head()\n",
    "\n",
    "# for docname in doclist['DOCID']:\n",
    "DOCS_DIR = '/media/ludwig/story/DecisionRunDocs/docs_28topics/'\n",
    "docs = []\n",
    "for docname in doclist['DOCID']:\n",
    "    with open(DOCS_DIR + docname) as fh:\n",
    "        docs.append(fh.read())\n",
    "        \n",
    "doclist['DOC'] = docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    2452\n",
       " 1    1081\n",
       " 0      94\n",
       "Name: CREDIBLE, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doclist[~doclist['DOCID'].duplicated()]['CREDIBLE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # of assessments per topic after duplicate cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exercise_scoliosis_NC.csv                                  738\n",
       "thermotherapy_osteoarthritis_C.csv                         438\n",
       "antibiotics_sinusitis_NC.csv                               380\n",
       "alprazolam_depression_NC.csv                               331\n",
       "beta-blockers_stroke_NC.csv                                232\n",
       "antibiotics_otitis_media_C.csv                             200\n",
       "surgery_cataract_removal_NC.csv                            150\n",
       "Spironolactone_high_blood_pressure_C.csv                   126\n",
       "Hormone_therapy_cardiovascular_disease_menopause_NC.csv    117\n",
       "antibiotics_laryngitis_NC.csv                              112\n",
       "pancreatic_enzymes_pancreatitis_C.csv                      111\n",
       "screening_breast_cancer_C.csv                              106\n",
       "vaccine_hepatitis_B_NC.csv                                 101\n",
       "exercise_diabetes_C.csv                                     91\n",
       "echinacea_common_cold_C.csv                                 89\n",
       "exercise_neck_pain_C.csv                                    81\n",
       "screening_breast_cancer_NC.csv                              60\n",
       "garlic_for_common_cold_NC.csv                               57\n",
       "antibiotics_sore_throats_C.csv                              38\n",
       "garlic_common_cold_NC.csv                                   29\n",
       "vinpocetine_dementia_C.csv                                  18\n",
       "Hormone_therapy_cardiovascular_disease_menopause_C.csv      10\n",
       "antioxidants_female_subfertility_NC2.csv                     7\n",
       "antibiotics_bronchitis_NC.csv                                4\n",
       "antioxidants_female_subfertility_NC.csv                      1\n",
       "Name: SOURCE, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doclist = doclist[~doclist['DOCID'].duplicated()]\n",
    "doclist['SOURCE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(doclist,test_size = .2, random_state = 156)\n",
    "X_train = train['DOC'].values.tolist()\n",
    "X_test  = test['DOC'].values.tolist()\n",
    "y_train, y_test = train['CREDIBLE'], test['CREDIBLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='char', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(4, 4), preprocessor=None, stop_words=None,\n",
       "        ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Input to sklearn\n",
    "vect = CountVectorizer(ngram_range=(4,4), analyzer='char', binary=True)\n",
    "logreg = LogisticRegression()\n",
    "pline  = Pipeline([('vectorizer', vect), ('logreg', logreg)])\n",
    "pline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test): 0.9435261707988981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[478,   0,   8],\n",
       "       [ 11,   3,  10],\n",
       "       [ 10,   2, 204]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class = pline.predict(X_test)\n",
    "print('Accuracy (Test):', metrics.accuracy_score(y_test, y_pred_class))\n",
    "# print('Test F1 score (Test):', metrics.f1_score(y_test, y_pred_class, average='macro'))\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kfold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test): 0.928374655647383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test): 0.9614325068870524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test): 0.9586776859504132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test): 0.9476584022038568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test): 0.9586776859504132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test): 0.9559228650137741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test): 0.9421487603305785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test): 0.914364640883978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test): 0.9419889502762431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Test): 0.9447513812154696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=156, shuffle=True)\n",
    "res = []\n",
    "\n",
    "for train_index, test_index in kf.split(doclist):\n",
    "#     print(train_index, test_index)\n",
    "    X_train = doclist.iloc[train_index,:]['DOC'].values.tolist()\n",
    "    X_test  = doclist.iloc[test_index,:]['DOC'].values.tolist()\n",
    "    y_train, y_test = doclist.iloc[train_index,:]['CREDIBLE'], doclist.iloc[test_index,:]['CREDIBLE']\n",
    "#     print(len(X_train),len(X_test),len(y_train),len(y_test))\n",
    "    ## Input to sklearn\n",
    "    vect = CountVectorizer(ngram_range=(4,4), analyzer='char', binary=True)\n",
    "    logreg = LogisticRegression()\n",
    "    pline  = Pipeline([('vectorizer', vect), ('logreg', logreg)])\n",
    "    pline.fit(X_train, y_train)\n",
    "    y_pred_class = pline.predict(X_test)\n",
    "    print('Accuracy (Test):', metrics.accuracy_score(y_test, y_pred_class))\n",
    "    res.append(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.928374655647383,\n",
       " 0.9614325068870524,\n",
       " 0.9586776859504132,\n",
       " 0.9476584022038568,\n",
       " 0.9586776859504132,\n",
       " 0.9559228650137741,\n",
       " 0.9421487603305785,\n",
       " 0.914364640883978,\n",
       " 0.9419889502762431,\n",
       " 0.9447513812154696]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9453997534359162"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(res)/len(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kfold validation by topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = sorted(doclist['SOURCE'].value_counts().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_nonchange = ['antibiotics_bronchitis','exercise_scoliosis','garlic_for_common_cold', 'garlic_common_cold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [t.replace('_C.csv','') for t in topics]\n",
    "topics = [t.replace('_NC.csv','') for t in topics]\n",
    "topics = [t.replace('_NC2.csv','') for t in topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate(lst):\n",
    "    c   = [l + '_C.csv' for l in lst]\n",
    "    nc  = [l + '_NC.csv' for l in lst]\n",
    "    nc2 = [l + '_NC2.csv' for l in lst]\n",
    "    return(c + nc + nc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_change = list(set(topics) - set(topics_nonchange))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf   = KFold(n_splits = 5, random_state = 156, shuffle = True)\n",
    "splt = kf.split(topics_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6070143884892086\n",
      "0.3349019607843137\n",
      "0.8895663956639567\n",
      "0.6518987341772152\n",
      "0.9299610894941635\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "\n",
    "for train_index, test_index in splt:\n",
    "    vect = CountVectorizer(ngram_range=(4,4), analyzer='char', binary=True)\n",
    "    logreg = LogisticRegression()\n",
    "    pline  = Pipeline([('vectorizer', vect), ('logreg', logreg)])\n",
    "    test_topics  = [topics_change[t] for t in test_index]\n",
    "    train_topics = [topics_change[t] for t in train_index]\n",
    "    train_topics = train_topics + topics_nonchange\n",
    "    train_topics = populate(train_topics)\n",
    "    test_topics  = populate(test_topics)\n",
    "    train, test  = doclist[~doclist['SOURCE'].isin(test_topics)], doclist[doclist['SOURCE'].isin(test_topics)]\n",
    "    train        = train[~train['DOCID'].isin(test['DOCID'])]\n",
    "    X_train      = train['DOC'].values.tolist()\n",
    "    X_test       = test['DOC'].values.tolist()\n",
    "    y_train, y_test = train['CREDIBLE'], test['CREDIBLE']\n",
    "    vect = CountVectorizer(ngram_range=(4,4), analyzer='char', binary=True)\n",
    "    logreg = LogisticRegression()\n",
    "    pline  = Pipeline([('vectorizer', vect), ('logreg', logreg)])\n",
    "    pline.fit(X_train, y_train)\n",
    "    y_pred_class = pline.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "    accs.append(metrics.accuracy_score(y_test, y_pred_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6826685137217716"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(accs)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf   = KFold(n_splits = 10, random_state = 156, shuffle = True)\n",
    "splt = kf.split(topics_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8581314878892734\n",
      "0.5224787363304981\n",
      "0.46348733233979134\n",
      "0.19536423841059603\n",
      "0.9904264577893821\n",
      "0.45871559633027525\n",
      "0.6837209302325581\n",
      "0.8818181818181818\n",
      "1.0\n",
      "0.6732673267326733\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "\n",
    "for train_index, test_index in splt:\n",
    "    vect = CountVectorizer(ngram_range=(4,4), analyzer='char', binary=True)\n",
    "    logreg = LogisticRegression()\n",
    "    pline  = Pipeline([('vectorizer', vect), ('logreg', logreg)])\n",
    "    test_topics  = [topics_change[t] for t in test_index]\n",
    "    train_topics = [topics_change[t] for t in train_index]\n",
    "    train_topics = train_topics + topics_nonchange\n",
    "    train_topics = populate(train_topics)\n",
    "    test_topics  = populate(test_topics)\n",
    "    train, test  = doclist[~doclist['SOURCE'].isin(test_topics)], doclist[doclist['SOURCE'].isin(test_topics)]\n",
    "    train        = train[~train['DOCID'].isin(test['DOCID'])]\n",
    "    X_train      = train['DOC'].values.tolist()\n",
    "    X_test       = test['DOC'].values.tolist()\n",
    "    y_train, y_test = train['CREDIBLE'], test['CREDIBLE']\n",
    "    vect = CountVectorizer(ngram_range=(4,4), analyzer='char', binary=True)\n",
    "    logreg = LogisticRegression()\n",
    "    pline  = Pipeline([('vectorizer', vect), ('logreg', logreg)])\n",
    "    pline.fit(X_train, y_train)\n",
    "    y_pred_class = pline.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "    accs.append(metrics.accuracy_score(y_test, y_pred_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6727410287873229"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(accs)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf   = KFold(n_splits = 10, random_state = 156, shuffle = True)\n",
    "splt = kf.split(topics_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21933085501858737\n",
      "0.5198187995469988\n",
      "0.8475750577367206\n",
      "0.8995983935742972\n",
      "0.5350877192982456\n",
      "0.6196377502383222\n",
      "0.9236111111111112\n",
      "0.9188118811881189\n",
      "0.5742574257425742\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "\n",
    "for train_index, test_index in splt:\n",
    "    test_topics  = [topics_change[t] for t in test_index]\n",
    "    train_topics = [topics_change[t] for t in train_index]\n",
    "    train_topics = train_topics + topics_nonchange\n",
    "    train_topics = populate(train_topics)\n",
    "    test_topics  = populate(test_topics)\n",
    "    train, test  = doclist[~doclist['SOURCE'].isin(test_topics)], doclist[doclist['SOURCE'].isin(test_topics)]\n",
    "    train        = train[~train['DOCID'].isin(test['DOCID'])]\n",
    "    train        = train[~train['DOCID'].duplicated()]\n",
    "    test         = test[~test['DOCID'].duplicated()]\n",
    "    X_train      = train['DOC'].values.tolist()\n",
    "    X_test       = test['DOC'].values.tolist()\n",
    "    y_train, y_test = train['CREDIBLE'], test['CREDIBLE']\n",
    "    vect = CountVectorizer(ngram_range=(4,4), analyzer='char', binary=True)\n",
    "    logreg = LogisticRegression()\n",
    "    pline  = Pipeline([('vectorizer', vect), ('logreg', logreg)])\n",
    "    pline.fit(X_train, y_train)\n",
    "    y_pred_class = pline.predict(X_test)\n",
    "    print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "    accs.append(metrics.accuracy_score(y_test, y_pred_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6724395660121643"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(accs)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.219, 0.52, 0.848, 0.9, 0.535, 0.62, 0.924, 0.919, 0.574, 0.667]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[round(a,3) for a in accs]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
